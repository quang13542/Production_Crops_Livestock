{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyspark==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "# from pyspark.sql.functions import array, col\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#                     .master(\"spark://127.0.0.1:7077\") \\\n",
    "#                     .appName('AnnualValue') \\\n",
    "#                     .getOrCreate()\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[1]\") \\\n",
    "                    .appName('AnnualValue') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcl_df = spark.read.option(\"header\", True)\\\n",
    "    .csv(f\"{cwd}/dataset/Production_Crops_Livestock_E_All_Data/Production_Crops_Livestock_E_All_Data.csv\")\n",
    "# pcl_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in pcl_df.dtypes:\n",
    "    col_name.append(col[0])\n",
    "# col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = []\n",
    "for x in col_name:\n",
    "    if 'Y' in x and 'F' not in x:\n",
    "        year_list.append(int(x.replace('Y', '')))\n",
    "# year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElementProd_df = pcl_df.select(\n",
    "    pcl_df['Element Code'].cast('int').alias('id'),\n",
    "    pcl_df['Element'].cast('string').alias('element'),\n",
    "    pcl_df['Unit'].cast('string').alias('unit'),\n",
    ").orderBy('id')\n",
    "ElementProd_df = ElementProd_df.dropDuplicates([\"id\"])\n",
    "ElementProd_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_list:\n",
    "    pcl_df = pcl_df.withColumn(f\"NewColumn_{year}\", F.array(f\"Y{year}\", f\"Y{year}F\", F.lit(year)))\n",
    "    pcl_df = pcl_df.drop(f\"Y{year}\", f\"Y{year}F\")\n",
    "    \n",
    "pcl_df = pcl_df.withColumn(f\"merge_column\", F.array(*[f\"NewColumn_{year}\" for year in year_list]))\n",
    "transformed_date = datetime.datetime.now()\n",
    "for year in year_list:\n",
    "    pcl_df = pcl_df.drop(f\"NewColumn_{year}\")\n",
    "pcl_df = pcl_df..withColumn(\"id\", F.monotonically_increasing_id()) \\\n",
    "                .select(\n",
    "                    pcl_df['id'].cast('int'),\n",
    "                    pcl_df['Area Code'].cast('int').alias('country_id'),\n",
    "                    pcl_df['Item Code'].cast('int').alias('item_prod_id'),\n",
    "                    pcl_df['Element Code'].cast('int').alias('element_prod_id'),\n",
    "                    F.explode('merge_column').alias('year_col')\n",
    "                )\n",
    "pcl_df = pcl_df.withColumn('value', F.lit(pcl_df.year_col[0])) \\\n",
    "                .withColumn('flag', F.lit(pcl_df.year_col[1])) \\\n",
    "                .withColumn('year', F.lit(pcl_df.year_col[2])) \\\n",
    "                .withColumn('transformed_date', F.lit(transformed_date))\n",
    "pcl_df = pcl_df.drop('year_col')\n",
    "pcl_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcl_df.write\\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .parquet(\"hdfs://127.0.0.1:9000/FAOSTAT_prj/DataWarehouse/Production_Crops_Livestock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pcl_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(spark.read.parquet(\"hdfs://127.0.0.1:9000/FAOSTAT_prj/DataWarehouse/Production_Crops_Livestock\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
