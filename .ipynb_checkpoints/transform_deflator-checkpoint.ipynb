{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyspark==3.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "# from pyspark.sql.functions import array, col\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder \\\n",
    "#                     .master(\"spark://127.0.0.1:7077\") \\\n",
    "#                     .appName('Deflator') \\\n",
    "#                     .getOrCreate()\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('Deflator') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_df = spark.read.option(\"header\", True)\\\n",
    "    .csv(f\"{cwd}/dataset/Deflators_E_All_Data/Deflators_E_All_Data.csv\")\n",
    "# d_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = []\n",
    "for col in d_df.dtypes:\n",
    "    col_name.append(col[0])\n",
    "# col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = []\n",
    "for x in col_name:\n",
    "    if 'Y' in x and 'F' not in x:\n",
    "        year_list.append(int(x.replace('Y', '')))\n",
    "# year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----+\n",
      "|  id|             element|unit|\n",
      "+----+--------------------+----+\n",
      "|6179|Value US$, 2015 p...| US$|\n",
      "|6180|Value Local Curre...| LCU|\n",
      "+----+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ElementDeflator_df = d_df.select(\n",
    "    d_df['Element Code'].cast('int').alias('id'),\n",
    "    d_df['Element'].cast('string').alias('element'),\n",
    "    d_df['Unit'].cast('string').alias('unit'),\n",
    ").orderBy('id')\n",
    "ElementDeflator_df = ElementDeflator_df.dropDuplicates([\"id\"])\n",
    "ElementDeflator_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|                item|\n",
      "+-----+--------------------+\n",
      "|22024|        GDP Deflator|\n",
      "|22025|Gross Fixed Capit...|\n",
      "|22026|Value Added Defla...|\n",
      "|22028|Value Added Defla...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ItemDeflator_df = d_df.select(\n",
    "    d_df['Item Code'].cast('int').alias('id'),\n",
    "    d_df['Item'].cast('string').alias('item'),\n",
    ").orderBy('id')\n",
    "ItemDeflator_df = ItemDeflator_df.dropDuplicates([\"id\"])\n",
    "ItemDeflator_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+-------------------+------------+----+----+--------------------+\n",
      "|country_id|item_deflator_id|element_deflator_id|       value|flag|year|    transformed_date|\n",
      "+----------+----------------+-------------------+------------+----+----+--------------------+\n",
      "|         2|           22024|               6180|0.0121732610|   E|1970|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0127808140|   E|1971|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0133249140|   E|1972|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0140519150|   E|1973|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0162203650|   E|1974|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0172100080|   E|1975|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0176550000|   E|1976|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0207030270|   E|1977|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0222818280|   E|1978|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0245115230|   E|1979|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0257340090|   E|1980|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0269012130|   E|1981|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0269794020|   E|1982|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0257017130|   E|1983|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0247890200|   E|1984|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0243561440|   E|1985|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0237197630|   E|1986|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0230112280|   E|1987|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0229382130|   E|1988|2023-07-25 16:29:...|\n",
      "|         2|           22024|               6180|0.0291145640|   E|1989|2023-07-25 16:29:...|\n",
      "+----------+----------------+-------------------+------------+----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for year in year_list:\n",
    "    d_df = d_df.withColumn(f\"NewColumn_{year}\", F.array(f\"Y{year}\", f\"Y{year}F\", F.lit(year)))\n",
    "    d_df = d_df.drop(f\"Y{year}\", f\"Y{year}F\")\n",
    "    \n",
    "d_df = d_df.withColumn(f\"merge_column\", F.array(*[f\"NewColumn_{year}\" for year in year_list]))\n",
    "transformed_date = datetime.datetime.now()\n",
    "for year in year_list:\n",
    "    d_df = d_df.drop(f\"NewColumn_{year}\")\n",
    "d_df = d_df.select(\n",
    "    d_df['Area Code'].cast('int').alias('country_id'),\n",
    "    d_df['Item Code'].cast('int').alias('item_deflator_id'),\n",
    "    d_df['Element Code'].cast('int').alias('element_deflator_id'),\n",
    "    F.explode('merge_column').alias('year_col')\n",
    ")\n",
    "d_df = d_df.withColumn('value', F.lit(d_df.year_col[0])) \\\n",
    "            .withColumn('flag', F.lit(d_df.year_col[1])) \\\n",
    "            .withColumn('year', F.lit(d_df.year_col[2])) \\\n",
    "            .withColumn('transformed_date', F.lit(transformed_date))\n",
    "d_df = d_df.drop('year_col')\n",
    "d_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_df.write\\\n",
    "#         .partitionBy(\"area_code\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .csv(f\"{cwd}/Transform_Data/Deflators_area_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_df.write\\\n",
    "#         .partitionBy(\"year\") \\\n",
    "#         .mode(\"overwrite\") \\\n",
    "#         .csv(f\"{cwd}/Transform_Data/Deflators_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
